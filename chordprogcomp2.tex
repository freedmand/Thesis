\subsection{Minimum Edit Distance}

Minimum edit distance, or the \textit{Levenshtein distance}, is a distance metric that computes the minimum number of operations needed to transform one sequence into the other using \textit{deletion}, \textit{insertion}, and \textit{substitution}. Deletion entails removing an item from the sequence being transformed, insertion adding one item to the sequence, and substitution replacing an item from the sequence with another item. Each operation entails a cost, and the function finds the minimal cost to transform one sequence into the other.

The technique is most commonly applied to \textit{string matching} in which two strings of text are compared. For instance, assuming all operations are of equal cost, the minimum number of transformations needed to transform \texttt{MORDENT}, a rapid alteration of notes, to \texttt{MODESTO}, a modest musical mood, is 3:

\[\texttt{MORDENT}\]
Apply \textit{deletion} on \texttt{R}:
\[\texttt{MODENT}\]
Apply \textit{substitution} to change \texttt{N} to \texttt{S}:
\[\texttt{MODEST}\]
Apply \textit{insertion} to add an \texttt{O} at the end:
\[\texttt{MODESTO}\]

This alignment can be represented as follows:

{\centering
\begin{tabular}{cccccccc}
\makebox[0.5cm]{\texttt{M}} & \makebox[0.5cm]{\texttt{O}} & \makebox[0.5cm]{\texttt{R}} & \makebox[0.5cm]{\texttt{D}} & \makebox[0.5cm]{\texttt{E}} & \makebox[0.5cm]{\texttt{N}} & \makebox[0.5cm]{\texttt{T}} & \makebox[0.5cm]{*} \\
\makebox[0.5cm]{$|$} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{Del} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{Sub} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{Add} \\
\makebox[0.5cm]{\texttt{M}} & \makebox[0.5cm]{\texttt{O}} & \makebox[0.5cm]{*} & \makebox[0.5cm]{\texttt{D}} & \makebox[0.5cm]{\texttt{E}} & \makebox[0.5cm]{\texttt{S}} & \makebox[0.5cm]{\texttt{T}} & \makebox[0.5cm]{\texttt{O}} \\
\end{tabular}
}

Though minimum edit distance is frequently run on plaintext strings, there are no limitations to its alphabet. It can be easily abstracted to the alphabet of musical chords.

The advantages of minimum edit distance are that it can compensate well for small errors at the global level of comparison. For instance, if there are two sequences of chords that are identical except for one minor error of transcription in the middle of the first chord progression, minimum edit distance will only penalize the error with one deletion operation, a cost of 1, rather than an exponential decrease in score as is the case with simple global comparison (see section~\ref{simpleglobal}). Additionally, minimum edit distance is a \textit{dynamic programming} algorithm, which means it solves a seemingly very complex problem by breaking it down into subproblems, and its overall runtime is quadratic.

The primary disadvantage of minimum edit distance is that it can only be used to find global alignments between songs and does not harness the power of local alignments.

\subsection{Smith-Waterman}

The Smith-Waterman algorithm\cite{smith1981identification} combines the power of minimum edit distance with extensible substitution and gap costs and serves to find the region of optimal local similarity between two sequences rather than global. This means that the algorithm can locate, similar to the n-grams approach, similar subsequences at all positions of both sequences and optimize a similarity measure; unlike n-grams, Smith-Waterman also optimizes all possible lengths of subsequences. Like minimum edit distance, the algorithm can be solved in quadratic time as it breaks down the complex task into computationally tractable subproblems. Though often used in bioinformatics and molecular applications with DNA or Protein alphabets, there is no reason the alphabet used cannot be abstracted to chord symbols.

The algorithm runs with the following functions, $S$ and $W$. $S$ is the substitution function, also referred to as a \textit{cost matrix}, and defines the cost of transforming one symbol to the other. $W$ refers to the gap function and assigns a cost to a gap of integer length, where a gap is essentially a combination of insertion or deletion operators. It is common to define a ${gap}_{open}$ constant and a ${gap}_{extension}$ constant such that $W(i) = \begin{cases} -{gap}_{open} - {gap}_{extension} \cdot (i - 1) &\text{if }i >= 1 \\ 0 &\text{if }i = 0 \end{cases}$.

% Sequence alignment refers to the computational task of trying to find common subsequences within two different sequences with minimal gaps. As a simplified example, consider trying to align the following words:

% % -atte
% %  || |
% % pat-e

% \section{Smith-Waterman Algorithm}

% The Smith-Waterman algorithm is used to find optimal local alignments between two sequences based on a cost matrix for symbols of the alphabet being used and defined gap costs.

Given two sequences $a$ and $b$ of length $m$ an $n$, a matrix $H$ of size $m \times n$ is constructed in the following manner by first populating the first row and column with zeros ($H(x,y)$ is the matrix element retrieval notation where $x$ corresponds to column and $y$ corresponds to row):

\begin{align*}
H(i,0) &= 0, 0 \leq i \leq m \\
H(0,j) &= 0, 0 \leq j \leq n \\
\end{align*}

Subsequently, the matrix is traversed from the top-left across rows to the bottom-right, building off of previous elements with a recurrence relation as follows:
\[ H(i,j) = \hbox{max} \begin{cases} 0 \\ H(i-1,j-1)+S(a_i,b_j) \\ \hbox{max}_{k \geq 1} \left\{ H(i-k,j)+W(k) \right\} \\ \hbox{max}_{l \geq 1}\left\{ H(i, j-l)+W(l)) \right\} \end{cases}  \]

The maximal element of the resulting matrix, $\max H$, defines the Smith-Waterman score, the maximum score within any two localized regions between two sequences based on the cost of transformation and gap penalties. This localized region can be thought of as two sliding windows, one for each song, similar to the approach in the n-grams chord progression comparisons, but for this approach each window can be of arbitrary size and the combination of sizes and positions that maximizes the score is chosen.

To retrieve positional information from a completed $H$ matrix, it is helpful to look at an example of the Smith-Waterman algorithm in action. Let the following chord progressions be represented as sequences $a$ and $b$:

\begin{align*}
a &= [C, F, C, G, F, C, G, Dm, C] \\
b &= [F, C, Dm, G, F, C, Dm, C, F] \\
\end{align*}

This example uses an application of the simple equality chord distance measure \[C_d(c_1,c_2) = \begin{cases} 4 &\text{if }root(c_1) = root(c_2) \lor (nochord(c_1) \land nochord(c_2) \\ -3 &\text{otherwise} \end{cases} \]
and a simplified gap cost of: \[W(i) = -i\]

The matrix is constructed with an empty first row and column (represented with a \textit{---}) and then completed according to the recurrence relation:

\[
\begin{pmatrix} & - & Cmaj & Fmaj & Cmaj & Gmaj & Fmaj & Cmaj & Gmaj & Dmin & Cmaj & \\ - & 0 & \color{blue}0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\ Fmaj & 0 & 0 & \color{blue}4 & 0 & 0 & 4 & 0 & 0 & 0 & 0 & \\ Cmaj & 0 & 4 & 0 & \color{blue}8 & 4 & 0 & 8 & 4 & 0 & 4 & \\ Dmin & 0 & 0 & 1 & \color{blue}4 & 5 & 1 & 4 & 5 & 8 & 4 & \\ Gmaj & 0 & 0 & 0 & 0 & \color{blue}8 & 4 & 0 & 8 & 4 & 5 & \\ Fmaj & 0 & 0 & 4 & 0 & 4 & \color{blue}{12} & 8 & 4 & 5 & 1 & \\ Cmaj & 0 & 4 & 0 & 8 & 4 & 8 & \color{blue}{16} & \color{blue}{12} & 8 & 9 & \\ Dmin & 0 & 0 & 1 & 4 & 5 & 4 & 12 & 13 & \color{blue}{16} & 12 & \\ Cmaj & 0 & 4 & 0 & 5 & 1 & 2 & 8 & 9 & 12 & \color{red}{20} & \\ Fmaj & 0 & 0 & 8 & 4 & 2 & 5 & 4 & 5 & 8 & 16 & \\ \end{pmatrix}
 \]
 
 The numbers colored blue show the elements that were used in the path to the maximal score, 20, colored red. The path can be backtracked using arrows:
 
 \[
\begin{pmatrix} & - & Cmaj & Fmaj & Cmaj & Gmaj & Fmaj & Cmaj & Gmaj & Dmin & Cmaj & \\ - & 0 & \color{blue}0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\ Fmaj & 0 & 0 & \color{blue}\nwarrow & 0 & 0 & 4 & 0 & 0 & 0 & 0 & \\ Cmaj & 0 & 4 & 0 & \color{blue}\nwarrow & 4 & 0 & 8 & 4 & 0 & 4 & \\ Dmin & 0 & 0 & 1 & \color{blue}\uparrow & 5 & 1 & 4 & 5 & 8 & 4 & \\ Gmaj & 0 & 0 & 0 & 0 & \color{blue}\nwarrow & 4 & 0 & 8 & 4 & 5 & \\ Fmaj & 0 & 0 & 4 & 0 & 4 & \color{blue}{\nwarrow} & 8 & 4 & 5 & 1 & \\ Cmaj & 0 & 4 & 0 & 8 & 4 & 8 & \color{blue}{\nwarrow} & \color{blue}{\leftarrow} & 8 & 9 & \\ Dmin & 0 & 0 & 1 & 4 & 5 & 4 & 12 & 13 & \color{blue}{\nwarrow} & 12 & \\ Cmaj & 0 & 4 & 0 & 5 & 1 & 2 & 8 & 9 & 12 & \color{red}{\nwarrow} & \\ Fmaj & 0 & 0 & 8 & 4 & 2 & 5 & 4 & 5 & 8 & 16 & \\ \end{pmatrix}
 \]

Enumerating the path from the red arrow results in the following sequence of arrows\[ [\nwarrow, \nwarrow, \leftarrow, \nwarrow, \nwarrow, \nwarrow, \uparrow, \nwarrow, \nwarrow] \]
which can be applied to a bijection \[ operationFromArrow(arrow) = \begin{cases} \textit{substitution} &\text{if }arrow = \nwarrow \\ \textit{deletion} &\text{if }arrow = \leftarrow \\ \textit{insertion} &\text{if }arrow = \uparrow \end{cases} \]
and reversed to produce the sequence:
\[ [substitution, substitution, insertion, substitution, substition, substitution, deletion, substitution, substitution] \]



% C, F, C, *,  G, F, C, G,  Dm, C
%   |  |  ins |  |  |  del |   |
%   F, C, Dm, G, F, C, *,  Dm, C, F


\item Localized comparison, dynamic programming, find minimum number of required "transformations" and optimal localized slice. Dynamic programming

\item Works well with inexact data, can deal with common pitfalls of chord extraction.

\item Isolates similar substructures.

\item Does not penalize closely related chords, i.e. Em7 and Gmaj

\item Difficulty in extracting multiple "best" options but good at finding one top contender

\item Difficulty in comparing scores

\subsection{Example Smith-Waterman Algorithm}

The following example shows how the Smith-Waterman algorithm could be applied to the alphabet of musical chord symbols:

This example assumes the following costs:

If the chord begins on the same root, then add 3 \\
Otherwise, subtract 4 \\