\subsection{Minimum Edit Distance}

Minimum edit distance, or the \textit{Levenshtein distance}, is a distance metric that computes the minimum number of operations needed to transform one sequence into the other using \textit{deletion}, \textit{insertion}, and \textit{substitution}. Deletion entails removing an item from the sequence being transformed, insertion adding one item to the sequence, and substitution replacing an item from the sequence with another item. Each operation entails a cost, and the algorithm finds the minimal cost to transform one sequence into the other in quadratic time.

The technique is most commonly applied to \textit{string matching} in which two strings of text are compared. For instance, assuming all operations are of equal cost, the minimum number of transformations needed to transform \texttt{MORDENT}, a rapid alteration of notes, to \texttt{MODESTO}, a modest musical mood, is 3:

\texttt{MORDENT}
Apply \textit{deletion} on \texttt{R}:
\[\texttt{MODENT}\]
Apply \textit{substitution} to change \texttt{N} to \texttt{S}:
\[\texttt{MODEST}\]
Apply \textit{insertion} to add an \texttt{O} at the end:
\[\texttt{MODESTO}\]

Minimum edit distance is a \textit{dynamic programming} algorithm that solves a seemingly very complex problem by breaking it down into subproblems.

\item Global comparison, assign cost to different edit distances and find minimum required "transformation" between two songs. Uses dynamic programming and can be done in quadratic time.

\item Disadvantages: global alignments only.

\subsection{Smith-Waterman}

Sequence alignment refers to the computational task of trying to find common subsequences within two different sequences with minimal gaps. As a simplified example, consider trying to align the following words:

% -atte
%  || |
% pat-e

\section{Smith-Waterman Algorithm}

The Smith-Waterman algorithm is used to find optimal local alignments between two sequences based on a cost matrix for symbols of the alphabet being used and defined gap costs.

A matrix $H$ is constructed in the following manner:
\[ H(i,0) = 0, 0 \leq i \leq m \]
\[ H(0,j) = 0, 0 \leq j \leq n \]
\[ H(i,j) = \hbox{max} \begin{cases} 0 \\ H(i-1,j-1)+s(a_i,b_j) \\ \hbox{max}_{k \geq 1} \left\{ H(i-k,j)+W_k \right\} \\ \hbox{max}_{l \geq 1}\left\{ H(i, j-l)+W_l) \right\} \end{cases}  \]

\item Localized comparison, dynamic programming, find minimum number of required "transformations" and optimal localized slice. Dynamic programming

\item Works well with inexact data, can deal with common pitfalls of chord extraction.

\item Isolates similar substructures.

\item Does not penalize closely related chords, i.e. Em7 and Gmaj

\item Difficulty in extracting multiple "best" options but good at finding one top contender

\item Difficulty in comparing scores

\subsection{Example Smith-Waterman Algorithm}

The following example shows how the Smith-Waterman algorithm could be applied to the alphabet of musical chord symbols:

\[ \begin{array}{cccccccc} & - & Cmaj & Fmaj & Cmaj & Gmaj & Fmaj & Cmaj & \\ - & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\ Cmaj & 0 & 3 & 0 & 3 & 0 & 0 & 3 & \\ Fmaj & 0 & 0 & 6 & 2 & 1 & 3 & 0 & \\ Dmin & 0 & 0 & 2 & 4 & 0 & 0 & 1 & \\ Gmaj & 0 & 0 & 0 & 0 & 7 & 3 & 0 & \\ Cmaj & 0 & 3 & 0 & 3 & 3 & 5 & 6 & \\ Gmaj & 0 & 0 & 1 & 0 & 6 & 2 & 3 & \\ Gmaj & 0 & 0 & 0 & 0 & 3 & 4 & 0 & \\ \end{array} \]

This example assumes the following costs:

If the chord begins on the same root, then add 3 \\
Otherwise, subtract 4 \\