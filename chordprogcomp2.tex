\subsection{Minimum Edit Distance}

Minimum edit distance, or the \textit{Levenshtein distance}, is a distance metric that computes the minimum number of operations needed to transform one sequence into the other using \textit{deletion}, \textit{insertion}, and \textit{substitution}. Deletion entails removing an item from the sequence being transformed, insertion adding one item to the sequence, and substitution replacing an item from the sequence with another item. Each operation entails a cost, and the function finds the minimal cost to transform one sequence into the other.

The technique is most commonly applied to \textit{string matching} in which two strings of text are compared. For instance, assuming all operations are of equal cost, the minimum number of transformations needed to transform \texttt{MORDENT}, a rapid alteration of notes, to \texttt{MODESTO}, a modest musical mood, is 3:

\[\texttt{MORDENT}\]
Apply \textit{deletion} on \texttt{R}:
\[\texttt{MODENT}\]
Apply \textit{substitution} to change \texttt{N} to \texttt{S}:
\[\texttt{MODEST}\]
Apply \textit{insertion} to add an \texttt{O} at the end:
\[\texttt{MODESTO}\]

This alignment can be represented as follows:

{\centering
\begin{tabular}{cccccccc}
\makebox[0.5cm]{\texttt{M}} & \makebox[0.5cm]{\texttt{O}} & \makebox[0.5cm]{\texttt{R}} & \makebox[0.5cm]{\texttt{D}} & \makebox[0.5cm]{\texttt{E}} & \makebox[0.5cm]{\texttt{N}} & \makebox[0.5cm]{\texttt{T}} & \makebox[0.5cm]{*} \\
\makebox[0.5cm]{$|$} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{Del} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{Sub} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{Ins} \\
\makebox[0.5cm]{\texttt{M}} & \makebox[0.5cm]{\texttt{O}} & \makebox[0.5cm]{*} & \makebox[0.5cm]{\texttt{D}} & \makebox[0.5cm]{\texttt{E}} & \makebox[0.5cm]{\texttt{S}} & \makebox[0.5cm]{\texttt{T}} & \makebox[0.5cm]{\texttt{O}} \\
\end{tabular}
}

Though minimum edit distance is frequently run on plaintext strings, there are no limitations to its alphabet. It can be easily abstracted to the alphabet of musical chords.

The advantages of minimum edit distance are that it can compensate well for small errors at the global level of comparison. For instance, if there are two sequences of chords that are identical except for one minor error of transcription in the middle of the first chord progression, minimum edit distance will only penalize the error with one deletion operation, a cost of 1, rather than an exponential decrease in score as is the case with simple global comparison (see section~\ref{simpleglobal}). Additionally, minimum edit distance is a \textit{dynamic programming} algorithm, which means it solves a seemingly very complex problem by breaking it down into subproblems, and its overall runtime is quadratic.

The primary disadvantage of minimum edit distance is that it can only be used to find global alignments between songs and does not harness the power of local alignments.

\subsection{Smith-Waterman}

The Smith-Waterman algorithm\cite{smith1981identification} combines the power of minimum edit distance with extensible substitution and gap costs and serves to find the region of optimal local similarity between two sequences rather than global. This means that the algorithm can locate, similar to the n-grams approach, similar subsequences at all positions of both sequences and optimize a similarity measure; unlike n-grams, Smith-Waterman also optimizes all possible lengths of subsequences. Like minimum edit distance, the algorithm can be solved in quadratic time as it breaks down the complex task into computationally tractable subproblems. Though often used in bioinformatics and molecular applications with DNA or Protein alphabets, there is no reason the alphabet used cannot be abstracted to chord symbols.

The algorithm runs with the following functions, $S$ and $W$. $S$ is the substitution function, also referred to as a \textit{cost matrix}, and defines the cost of transforming one symbol to the other. $W$ refers to the gap function and assigns a cost to a gap of integer length, where a gap is essentially a combination of insertion or deletion operators. It is common to define a ${gap}_{open}$ constant and a ${gap}_{extension}$ constant such that $W(i) = \begin{cases} -{gap}_{open} - {gap}_{extension} \cdot (i - 1) &\text{if }i >= 1 \\ 0 &\text{if }i = 0 \end{cases}$.

% Sequence alignment refers to the computational task of trying to find common subsequences within two different sequences with minimal gaps. As a simplified example, consider trying to align the following words:

% % -atte
% %  || |
% % pat-e

% \section{Smith-Waterman Algorithm}

% The Smith-Waterman algorithm is used to find optimal local alignments between two sequences based on a cost matrix for symbols of the alphabet being used and defined gap costs.

Given two sequences $a$ and $b$ of length $m$ an $n$, a matrix $H$ of size $m \times n$ is constructed in the following manner by first populating the first row and column with zeros ($H(x,y)$ is the matrix element retrieval notation where $x$ corresponds to column and $y$ corresponds to row):

\begin{align*}
H(i,0) &= 0, 0 \leq i \leq m \\
H(0,j) &= 0, 0 \leq j \leq n \\
\end{align*}

Subsequently, the matrix is traversed from the top-left across rows to the bottom-right, building off of previous elements with a recurrence relation as follows:
\[ H(i,j) = \hbox{max} \begin{cases} 0 \\ H(i-1,j-1)+S(a_i,b_j) \\ \hbox{max}_{k \geq 1} \left\{ H(i-k,j)+W(k) \right\} \\ \hbox{max}_{l \geq 1}\left\{ H(i, j-l)+W(l)) \right\} \end{cases}  \]

The maximal element of the resulting matrix, $\max H$, defines the Smith-Waterman score ($SW$), the maximum score within any two localized regions between two sequences based on the cost of transformation and gap penalties. This localized region can be thought of as two sliding windows, one for each song, similar to the approach in the n-grams chord progression comparisons, but for this approach each window can be of arbitrary size and the combination of sizes and positions that maximizes the score is chosen.

\subsubsection{Example}

To retrieve positional information from a completed $H$ matrix, it is helpful to look at an example of the Smith-Waterman algorithm in action. Let the following chord progressions be represented as sequences $a$ and $b$:

\begin{align*}
a &= [F, C, Dm, G, F, C, Dm, C, F] \\
b &= [C, F, C, G, F, C, G, Dm, C] \\
\end{align*}

This example uses an application of the simple equality chord distance measure \[C_d(c_1,c_2) = \begin{cases} 4 &\text{if }root(c_1) = root(c_2) \lor (nochord(c_1) \land nochord(c_2) \\ -3 &\text{otherwise} \end{cases} \]
and a simplified gap cost of: \[W(i) = -i\]

The matrix is constructed with an empty first row and column (represented with a \textit{---}) and then completed according to the recurrence relation:

\[
\begin{pmatrix} & - & Cmaj & Fmaj & Cmaj & Gmaj & Fmaj & Cmaj & Gmaj & Dmin & Cmaj \\ - & 0 & \color{blue}0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\ Fmaj & 0 & 0 & \color{blue}4 & 0 & 0 & 4 & 0 & 0 & 0 & 0 & \\ Cmaj & 0 & 4 & 0 & \color{blue}8 & 4 & 0 & 8 & 4 & 0 & 4 & \\ Dmin & 0 & 0 & 1 & \color{blue}4 & 5 & 1 & 4 & 5 & 8 & 4 & \\ Gmaj & 0 & 0 & 0 & 0 & \color{blue}8 & 4 & 0 & 8 & 4 & 5 & \\ Fmaj & 0 & 0 & 4 & 0 & 4 & \color{blue}{12} & 8 & 4 & 5 & 1 & \\ Cmaj & 0 & 4 & 0 & 8 & 4 & 8 & \color{blue}{16} & \color{blue}{12} & 8 & 9 & \\ Dmin & 0 & 0 & 1 & 4 & 5 & 4 & 12 & 13 & \color{blue}{16} & 12 & \\ Cmaj & 0 & 4 & 0 & 5 & 1 & 2 & 8 & 9 & 12 & \color{red}{20} & \\ Fmaj & 0 & 0 & 8 & 4 & 2 & 5 & 4 & 5 & 8 & 16 & \\ \end{pmatrix}
 \]
 
 The numbers colored blue show the elements that were used in the path to the maximal score, 20, colored red. The path can be backtracked using arrows:
 
 \[
\begin{pmatrix} & - & Cmaj & Fmaj & Cmaj & Gmaj & Fmaj & Cmaj & Gmaj & Dmin & Cmaj & \\ - & 0 & \color{blue}0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ Fmaj & 0 & 0 & \color{blue}\nwarrow & 0 & 0 & 4 & 0 & 0 & 0 & 0\\ Cmaj & 0 & 4 & 0 & \color{blue}\nwarrow & 4 & 0 & 8 & 4 & 0 & 4\\ Dmin & 0 & 0 & 1 & \color{blue}\uparrow & 5 & 1 & 4 & 5 & 8 & 4\\ Gmaj & 0 & 0 & 0 & 0 & \color{blue}\nwarrow & 4 & 0 & 8 & 4 & 5\\ Fmaj & 0 & 0 & 4 & 0 & 4 & \color{blue}{\nwarrow} & 8 & 4 & 5 & 1\\ Cmaj & 0 & 4 & 0 & 8 & 4 & 8 & \color{blue}{\nwarrow} & \color{blue}{\leftarrow} & 8 & 9\\ Dmin & 0 & 0 & 1 & 4 & 5 & 4 & 12 & 13 & \color{blue}{\nwarrow} & 12\\ Cmaj & 0 & 4 & 0 & 5 & 1 & 2 & 8 & 9 & 12 & \color{red}{\nwarrow}\\ Fmaj & 0 & 0 & 8 & 4 & 2 & 5 & 4 & 5 & 8 & 16\\ \end{pmatrix}
 \]

Enumerating the path from the red arrow results in the following sequence of arrows\[ [\nwarrow, \nwarrow, \leftarrow, \nwarrow, \nwarrow, \nwarrow, \uparrow, \nwarrow, \nwarrow] \]
which can be applied to a bijection \[ operationFromArrow(arrow) = \begin{cases} \textit{substitution} &\text{if }arrow = \nwarrow \\ \textit{deletion} &\text{if }arrow = \leftarrow \\ \textit{insertion} &\text{if }arrow = \uparrow \end{cases} \]
and reversed to produce the sequence:
\[ [substitution, substitution, insertion, substitution, substition, substitution, deletion, substitution, substitution] \]

To show the optimal local alignment between both sequences, the appropriate subsections of both sequences need to be extracted. From $a$ this corresponds to the chords whose rows feature blue and red text \[ [F, C, Dm, G, F, C, Dm, C] \] and from $b$ this corresponds to the chords corresponding to the columns that feature blue and red text \[ [F, C, G, F, C, G, Dm, C] \]

Like the example in minimum edit distance, both sequences are aligned with one another. \textit{Substitution} operators are represented with vertical lines between corresponding elements. \text{Insertion} operators indicate a gap in the first sequence (represented with *) and a chord in the second sequence. Finally, \textit{deletion} operators correspond with a gap in the second sequence and a chord in the first sequence. $a$ and $b$ can then be stitched together, or \textit{aligned}, as follows:

{\centering
\begin{tabular}{ccccccccc}
\makebox[0.5cm]{$F$} & \makebox[0.5cm]{$C$} & \makebox[0.5cm]{$Dm$} & \makebox[0.5cm]{$G$} & \makebox[0.5cm]{$F$} & \makebox[0.5cm]{$C$} & \makebox[0.5cm]{*} & \makebox[0.5cm]{$Dm$} & \makebox[0.5cm]{$C$} \\
\makebox[0.5cm]{$|$} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{Ins} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{Del} & \makebox[0.5cm]{$|$} & \makebox[0.5cm]{$|$} \\
\makebox[0.5cm]{$F$} & \makebox[0.5cm]{$C$} & \makebox[0.5cm]{*} & \makebox[0.5cm]{$G$} & \makebox[0.5cm]{$F$} & \makebox[0.5cm]{$C$} & \makebox[0.5cm]{$G$} & \makebox[0.5cm]{$Dm$} & \makebox[0.5cm]{$C$} \\
\end{tabular}
}

\subsubsection{Use as a Chord Progression Similarity Measure}

Smith-Waterman is useful in the context of comparing chord progressions as it has mechanisms to deal well with inexact data, using different gap costs and chord distance substitution functions that compensate for small errors. Both the Harte distance metric and TPS can be easily used as a substitution function. For a given distance function $C_d$, gap costs ${gap}_{open}$ and ${gap}_{extension}$, the Smith-Waterman algorithm is: \[ \max_k^{12} SW(c1, t_k({c2}), C_d, W_i) \] where $C_d$ corresponds to the $S$ substitution cost function in the Smith-Waterman algorithm and $W_i$ the gap penalty function: \[ W(i) = \begin{cases} -{gap}_{open} - {gap}_{extension} \cdot (i - 1) &\text{if }i >= 1 \\ 0 &\text{if }i = 0 \end{cases} \] Essentially, the score that is returned is the maximum of all twelve transpositions of one sequence relative to the other.

Because of all its advantages and research that supports its efficacy\cite{hanna2009alignment}, the Smith-Waterman algorithm will be used to compare chord progressions in this paper. There are downsides to the Smith-Waterman algorithm. It can only be used to extract one optimal local alignment, and the score returned reflects only that local alignment, whereas n-grams comparison does well with multiple like regions of local similarity. There are adjustments to the algorithm to return multiple good alignments, but they prove computationally expensive. This paper focuses on only returning one good alignment. Another difficulty is that of comparing scores from different Smith-Waterman results on different data.

\subsubsection{Normalization}

\textit{Normalization} measures refer to attempts to make raw Smith-Waterman scores, which have a positive correlation with increased sequence length, invariant of sequence length through formulaic and statistical means. For notational convenience, $SW(c1,c2)$ will refer to a Smith-Waterman chord progression comparison score between two chord progressions without bothering with notating the chord distance and gap penalty function.

Statistical techniques comprise of collecting many samples of $SW$ scores of the sequences being tested in different shuffled permutations and deriving mean and standard-deviation factors\cite{smith1985statistical}. These techniques were not used after I wrote a program to collect this kind of data using two chord progressions and constructed a line plot of the result (see figure~\ref{fig:swplot}) in which $SW$ score is along the x-axis and number of occurrences out of 100,000 samples is on the y-axis. As can be seen, based on the chord distance function used (in this case simple equality), odd and even $SW$ score values have drastically different empirical probabilities of occurring.